# Config file for jet classification

#------------------------------------------------------------------
# Note: We will read processing parameters from the loaded file, 
# rather than from this config file.
# See subjets_unshuffled.h5 and subjet_graphs.h5 for the set
# of parameters that are read from the loaded file.
#------------------------------------------------------------------

#------------------------------------------------------------------
# These following parameters are used only in ML analysis
#------------------------------------------------------------------

# Size of labeled data to load (i.e. number of jets)
n_train: 1600000
n_val:   200000
n_test:  200000

# Which subjet collections to use
subjet_basis: 'inclusive'
r: [0.05]

# Classification labels
label_0: 'gluon'
label_1: 'quark'

# Select model: subjet_gcn_pytorch, subjet_gat_pytorch, particle_gcn_pytorch, particle_gat_pytorch, 
#               particle_net, particle_net_laman, particle_transformer, particle_transformer_laman
models: ['particle_transformer_laman']

particle_transformer:
    graph_types: ['disconnected'] # placeholder name for the graph type since the fully connected graph is constructed in the architecture script 
    batch_size: 256
    epochs: 18
    learning_rate: 0.001
    input_dim: 1 # number of input features, if 4: use 4dim feature space (pt, eta, phi, mass). If 1: use only the  pt of each particle.
    pair_input_dim: 4 # how many interaction terms for pair of particles. If 3: use (dR, k_t = min(pt_1, pt_2)*dR, z = min(pt_1, pt_2)/(pt_1 + pt_2) ), if 4: also use m^2 = (E1 + E2)^2 - (p1 + p2)^2    
    load_model: False # if True, load the pre-trained model from the path specified in the architecture script. Else, train the model from scratch.
    save_model: False # if True, save the trained model to the path specified in the architecture script. Else, do not save the model.

particle_transformer_laman:
    graph_types: ['disconnected'] # placeholder name for the graph type since the fully connected graph is constructed in the architecture script 
    batch_size: 256
    epochs: 18
    learning_rate: 0.001
    input_dim: 1 # number of input features, if 4: use 4dim feature space (pt, eta, phi, mass). If 1: use only the  pt of each particle.
    pair_input_dim: 4 
    load_model: False # if True, load the pre-trained model from the path specified in the architecture script. Else, train the model from scratch.
    save_model: False # if True, save the trained model to the path specified in the architecture script. Else, do not save the model.
    random_graph: False # if True, use random graphs. Else, use Laman graphs.
    add_angles: 15    # How many angles to add (+) or remove (-) from the Laman Graph. Currently only works with "random_graph: False" 
                      # The default is 0: When add_angles < 0 and  abs(add_angles)> n_particles^jet - 2, the graph will be disconnected, so in the code
                      # we set remove_angles = min(remove_angles, n_particles^jet - 2) to avoid this issue. 
                      # The average jet has ~40 particles and only ~2% of the jets have less than 15 particles.
                      # Conversely when add_angles > (n_particles^jet choose 2) - (2*n_particles^jet -3), the graph will be fully connected, so we stop there.
                      
particle_net:
    graph_types: ['disconnected'] # placeholder name for the graph type since no actual graph is used as input. The graph is constructed in the architecture script
    batch_size: 512
    epochs: 10
    learning_rate: 0.001
    three_momentum_features: True # if True, use the three momentum features (pt, eta, phi) as input features for the PN. Else, use the original 7dim feature space.
    original_train_parameters: False # if True, use the original training parameters from the paper https://arxiv.org/abs/1902.08570. So far the best hyperparameters for the particle_net model

particle_net_laman:
    graph_types: ['disconnected'] # placeholder name for the graph type since no actual graph is used
    batch_size: 512
    epochs: 10
    learning_rate: 0.001
    three_momentum_features: True # This has to be True. If set to False, it will be overwritten to True.
    original_train_parameters: False # if True, use the original training parameters from the paper https://arxiv.org/abs/1902.08570. So far the best hyperparameters for the particle_net model


particle_gcn_pytorch:
    graph_types: ['fully_connected']
    edge_features: False
    hidden_dim: 64
    batch_size: 512
    epochs: 15
    learning_rate: 0.001

particle_gat_pytorch:
    graph_types: ['fully_connected']
    edge_features: False
    hidden_dim: 8
    n_heads: 8
    batch_size: 512
    epochs: 15
    learning_rate: 0.001

subjet_gcn_pytorch:
    graph_types: ['laman_naive', 'laman_1N', 'laman_1N2N']
    edge_features: False
    hidden_dim: 64
    batch_size: 128
    epochs: 5
    learning_rate: 0.001

subjet_gat_pytorch:
    graph_types: ['laman_naive', 'laman_1N', 'laman_1N2N']
    edge_features: True
    hidden_dim: 8
    n_heads: 8
    batch_size: 128
    epochs: 5    
    learning_rate: 0.001
